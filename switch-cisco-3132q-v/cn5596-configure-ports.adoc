---
permalink: switch-cisco-3132q-v/cn5596-configure-ports.html
sidebar: sidebar
keywords: cisco 3132q-v, cluster switches
summary: "You can use Cisco Nexus 3132q-v switches as cluster switches in your AFF or FAS cluster."
---
= Configure your ports
:icons: font
:imagesdir: ../media/

[.lead]
Follow these steps to configure your ports for migration from the Nexus 5596 switches to the new Nexus 3132Q-V switches.

.Steps

. On all nodes, remove all cables attached to the Nexus 5596 switch CL2.
+
With supported cabling, reconnect disconnected ports on all nodes to the Nexus 3132Q-V switch C2.

. Remove all the cables from the Nexus 5596 switch CL2.
+
Attach the appropriate Cisco QSFP to SFP+ break-out cables connecting port 1/24 on the new Cisco 3132Q-V switch, C2, to ports 45 to 48 on existing Nexus 5596, CL1.

. Verify that interfaces eth1/45-48 already have `channel-group 1 mode active` in their running configuration.
. Bring up ISLs ports 45 through 48 on the active Nexus 5596 switch CL1.
+
.Show example
[%collapsible]
====
The following example shows ISLs ports 45 through 48 being brought up:

----
(CL1)# configure
(CL1)(Config)# interface e1/45-48
(CL1)(config-if-range)# no shutdown
(CL1)(config-if-range)# exit
(CL1)(Config)# exit
(CL1)#
----
====

. Verify that the ISLs are `up` on the Nexus 5596 switch CL1:
+
`show port-channel summary`
+
.Show example
[%collapsible]
====
Ports eth1/45 through eth1/48 should indicate (P) meaning that the ISL ports are `up` in the port-channel:

----
Example
CL1# show port-channel summary
Flags: D - Down         P - Up in port-channel (members)
       I - Individual   H - Hot-standby (LACP only)
       s - Suspended    r - Module-removed
       S - Switched     R - Routed
       U - Up (port-channel)
       M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-        Type   Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)      Eth    LACP      Eth1/41(D)   Eth1/42(D)   Eth1/43(D)
                                    Eth1/44(D)   Eth1/45(P)   Eth1/46(P)
                                    Eth1/47(P)   Eth1/48(P)
----
====

. Verify that the ISLs are `up` on the 3132Q-V switch C2:
+
`show port-channel summary`
+
.Show example
[%collapsible]
====
Ports eth1/24/1, eth1/24/2, eth1/24/3, and eth1/24/4 should indicate (P) meaning that the ISL ports are `up` in the port-channel:

----
C2# show port-channel summary
Flags: D - Down         P - Up in port-channel (members)
       I - Individual   H - Hot-standby (LACP only)
       s - Suspended    r - Module-removed
       S - Switched     R - Routed
       U - Up (port-channel)
       M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-        Type   Protocol  Member Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)      Eth    LACP      Eth1/31(D)   Eth1/32(D)
2     Po2(SU)      Eth    LACP      Eth1/24/1(P)  Eth1/24/2(P)  Eth1/24/3(P)
                                    Eth1/24/4(P)
----
====

. On all nodes, bring up all the cluster interconnect ports connected to the 3132Q-V switch C2:
+
`network port modify`
+
.Show example
[%collapsible]
====
The following example shows the specified ports being brought up on nodes n1 and n2:

----
cluster::*> network port modify -node n1 -port e0b -up-admin true
cluster::*> network port modify -node n1 -port e0c -up-admin true
cluster::*> network port modify -node n2 -port e0b -up-admin true
cluster::*> network port modify -node n2 -port e0c -up-admin true
----
====

. On all nodes, revert all of the migrated cluster interconnect LIFs connected to C2:
+
`network interface revert`
+
.Show example
[%collapsible]
====
The following example shows the migrated cluster LIFs being reverted to their home ports on nodes n1 and n2:

----
cluster::*> network interface revert -vserver Cluster -lif n1_clus2
cluster::*> network interface revert -vserver Cluster -lif n1_clus3
cluster::*> network interface revert -vserver Cluster -lif n2_clus2
cluster::*> network interface revert -vserver Cluster -lif n2_clus3
----
====

. Verify all the cluster interconnect ports are now reverted to their home:
+
`network interface show`
+
.Show example
[%collapsible]
====
The following example shows that the LIFs on clus2 reverted to their home ports and shows that the LIFs are successfully reverted if the ports in the Current Port column have a status of `true` in the `Is Home` column. If the `Is Home` value is `false`, the LIF has not been reverted.

----
cluster::*> network interface show -role cluster
(network interface show)
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            n1_clus1   up/up      10.10.0.1/24       n1            e0a     true
            n1_clus2   up/up      10.10.0.2/24       n1            e0b     true
            n1_clus3   up/up      10.10.0.3/24       n1            e0c     true
            n1_clus4   up/up      10.10.0.4/24       n1            e0d     true
            n2_clus1   up/up      10.10.0.5/24       n2            e0a     true
            n2_clus2   up/up      10.10.0.6/24       n2            e0b     true
            n2_clus3   up/up      10.10.0.7/24       n2            e0c     true
            n2_clus4   up/up      10.10.0.8/24       n2            e0d     true
8 entries were displayed.
----
====

. Verify that the clustered ports are connected:
+
`network port show`
+
.Show example
[%collapsible]
====
The following example shows the result of the previous `network port modify` command, verifying that all the cluster interconnects are `up`:

----
cluster::*> network port show -role cluster
  (network port show)
Node: n1
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000 auto/10000  -        -
e0b       Cluster      Cluster          up   9000 auto/10000  -        -
e0c       Cluster      Cluster          up   9000 auto/10000  -        -
e0d       Cluster      Cluster          up   9000 auto/10000  -        -

Node: n2
                                                                       Ignore
                                                  Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status   Status
--------- ------------ ---------------- ---- ---- ----------- -------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 -        -
e0b       Cluster      Cluster          up   9000  auto/10000 -        -
e0c       Cluster      Cluster          up   9000  auto/10000 -        -
e0d       Cluster      Cluster          up   9000  auto/10000 -        -
8 entries were displayed.
----
====

. Verify the connectivity of the remote cluster interfaces: 
+

// start of tabbed content

[role="tabbed-block"]

====

.ONTAP 9.9.1 and later

--
You can use the `network interface check cluster-connectivity` command to start an accessibility check for cluster connectivity and then display the details: 

`network interface check cluster-connectivity start` and `network interface check cluster-connectivity show`

[subs=+quotes]
----
cluster1::*> *network interface check cluster-connectivity start*
----

*NOTE:* Wait for a number of seconds before running the show command to display the details.


[subs=+quotes]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source          Destination       Packet
Node   Date                       LIF             LIF               Loss
------ -------------------------- --------------- ----------------- -----------
n1
       3/5/2022 19:21:18 -06:00   n1_clus2        n2_clus1      none
       3/5/2022 19:21:20 -06:00   n1_clus2        n2_clus2      none

n2
       3/5/2022 19:21:18 -06:00   n2_clus2        n1_clus1      none
       3/5/2022 19:21:20 -06:00   n2_clus2        n1_clus2      none
----
--

.All ONTAP releases
--
For all ONTAP releases, you can also use the `cluster ping-cluster -node <name>` command to check the connectivity:

`cluster ping-cluster -node <name>`

[subs=+quotes]
----
cluster::*> *cluster ping-cluster -node n1*
Host is n1
Getting addresses from network interface table...
Cluster n1_clus1 n1		e0a	10.10.0.1
Cluster n1_clus2 n1		e0b	10.10.0.2
Cluster n1_clus3 n1		e0c	10.10.0.3
Cluster n1_clus4 n1		e0d	10.10.0.4
Cluster n2_clus1 n2		e0a	10.10.0.5
Cluster n2_clus2 n2		e0b	10.10.0.6
Cluster n2_clus3 n2		e0c	10.10.0.7
Cluster n2_clus4 n2		e0d	10.10.0.8

Local = 10.10.0.1 10.10.0.2 10.10.0.3 10.10.0.4
Remote = 10.10.0.5 10.10.0.6 10.10.0.7 10.10.0.8
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 16 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 1500 byte MTU on 16 path(s):
    Local 10.10.0.1 to Remote 10.10.0.5
    Local 10.10.0.1 to Remote 10.10.0.6
    Local 10.10.0.1 to Remote 10.10.0.7
    Local 10.10.0.1 to Remote 10.10.0.8
    Local 10.10.0.2 to Remote 10.10.0.5
    Local 10.10.0.2 to Remote 10.10.0.6
    Local 10.10.0.2 to Remote 10.10.0.7
    Local 10.10.0.2 to Remote 10.10.0.8
    Local 10.10.0.3 to Remote 10.10.0.5
    Local 10.10.0.3 to Remote 10.10.0.6
    Local 10.10.0.3 to Remote 10.10.0.7
    Local 10.10.0.3 to Remote 10.10.0.8
    Local 10.10.0.4 to Remote 10.10.0.5
    Local 10.10.0.4 to Remote 10.10.0.6
    Local 10.10.0.4 to Remote 10.10.0.7
    Local 10.10.0.4 to Remote 10.10.0.8
Larger than PMTU communication succeeds on 16 path(s)
RPC status:
4 paths up, 0 paths down (tcp check)
4 paths up, 0 paths down (udp check)
----
--
====

// end of tabbed content

[start=12]


. [[step12]]On each node in the cluster, migrate the interfaces associated with the first Nexus 5596 switch, CL1, to be replaced:
+
`network interface migrate`
+
.Show example
[%collapsible]
====
The following example shows the ports or LIFs being migrated on nodes n1 and n2:

----
cluster::*> network interface migrate -vserver Cluster -lif n1_clus1 -source-node n1 -
destination-node n1 -destination-port e0b
cluster::*> network interface migrate -vserver Cluster -lif n1_clus4 -source-node n1 -
destination-node n1 -destination-port e0c
cluster::*> network interface migrate -vserver Cluster -lif n2_clus1 -source-node n2 -
destination-node n2 -destination-port e0b
cluster::*> network interface migrate -vserver Cluster -lif n2_clus4 -source-node n2 -
destination-node n2 -destination-port e0c
----
====

. Verify the cluster status:
+
`network interface show`
+
.Show example
[%collapsible]
====
The following example shows that the required cluster LIFs have been migrated to appropriate cluster ports hosted on cluster switch C2:

----
 (network interface show)
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            n1_clus1   up/up      10.10.0.1/24       n1            e0b     false
            n1_clus2   up/up      10.10.0.2/24       n1            e0b     true
            n1_clus3   up/up      10.10.0.3/24       n1            e0c     true
            n1_clus4   up/up      10.10.0.4/24       n1            e0c     false
            n2_clus1   up/up      10.10.0.5/24       n2            e0b     false
            n2_clus2   up/up      10.10.0.6/24       n2            e0b     true
            n2_clus3   up/up      10.10.0.7/24       n2            e0c     true
            n2_clus4   up/up      10.10.0.8/24       n2            e0c     false
8 entries were displayed.

----- ------- ----
----
====

. On all the nodes, shut down the node ports that are connected to CL1:
+
`network port modify`
+
.Show example
[%collapsible]
====
The following example shows the specified ports being shut down on nodes n1 and n2:

----
cluster::*> network port modify -node n1 -port e0a -up-admin false
cluster::*> network port modify -node n1 -port e0d -up-admin false
cluster::*> network port modify -node n2 -port e0a -up-admin false
cluster::*> network port modify -node n2 -port e0d -up-admin false
----
====

. Shut down the ISL ports 24, 31, and 32 on the active 3132Q-V switch C2: 
+
`shutdown`
+
.Show example
[%collapsible]
====
The following example shows how to shut down ISLs 24, 31, and 32:

----
C2# configure
C2(Config)# interface e1/24/1-4
C2(config-if-range)# shutdown
C2(config-if-range)# exit
C2(config)# interface 1/31-32
C2(config-if-range)# shutdown
C2(config-if-range)# exit
C2(config-if)# exit
C2#
----
====

. On all nodes, remove all cables attached to the Nexus 5596 switch CL1.
+
With supported cabling, reconnect disconnected ports on all nodes to the Nexus 3132Q-V switch C1.

. Remove the QSFP breakout cable from Nexus 3132Q-V C2 ports e1/24.
+
Connect ports e1/31 and e1/32 on C1 to ports e1/31 and e1/32 on C2 using supported Cisco QSFP optical fiber or direct-attach cables.

. Restore the configuration on port 24 and remove the temporary Port Channel 2 on C2:
+
----
C2# configure
C2(config)# no interface breakout module 1 port 24 map 10g-4x
C2(config)# no interface port-channel 2
C2(config-if)# int e1/24
C2(config-if)# description 40GbE Node Port
C2(config-if)# spanning-tree port type edge
C2(config-if)# spanning-tree bpduguard enable
C2(config-if)# mtu 9216
C2(config-if-range)# exit
C2(config)# exit
C2# copy running-config startup-config
[########################################] 100%
Copy Complete.
----

. Bring up ISL ports 31 and 32 on C2, the active 3132Q-V switch: `no shutdown`
+
.Show example
[%collapsible]
====
The following example shows how to bring up ISLs 31 and 32 on the 3132Q-V switch C2:

----
C2# configure
C2(config)# interface ethernet 1/31-32
C2(config-if-range)# no shutdown
C2(config-if-range)# exit
C2(config)# exit
C2# copy running-config startup-config
[########################################] 100%
Copy Complete.
----
====

.What's next?
link:cn5596-complete-migration.html[Complete your migration].

//Updates for internal GH issue #262, 2024-11-19
