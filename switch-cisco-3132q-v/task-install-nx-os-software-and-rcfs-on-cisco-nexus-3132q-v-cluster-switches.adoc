---
permalink: switch-cisco-3132q-v/task-install-nx-os-software-and-rcfs-on-cisco-nexus-3132q-v-cluster-switches.html
sidebar: sidebar
keywords: install, nx-os software, rcfs, cisco nexus 3132q-v, cluster switches
summary: "The Cisco NX-OS software and reference configuration files (RCFs) must be installed on Cisco Nexus 3132Q-V cluster switches."
---
= Prepare to install NX-OS and RCF
:icons: font
:imagesdir: ../media/

[.lead]
Before you install the NX-OS software and the Reference Configuration File (RCF), follow this procedure.

.About the examples
The examples in this procedure use two nodes. These nodes use two 10GbE cluster interconnect ports `e0a` and `e0b`.

See the link:https://hwu.netapp.com/SWITCH/INDEX[Hardware Universe^] to verify the correct cluster ports on your platforms.

NOTE: The command outputs might vary depending on different releases of ONTAP.

.Switch and node nomenclature
The examples in this procedure use the following switch and node nomenclature:

* The names of the two Cisco switches are `cs1` and `cs2`.
* The node names are `cluster1-01` and `cluster1-02`.
* The cluster LIF names are `cluster1-01_clus1` and `cluster1-01_clus2` for cluster1-01 and `cluster1-02_clus1` and `cluster1-02_clus2` for cluster1-02.
* The `cluster1::*>` prompt indicates the name of the cluster.

NOTE: The procedure requires the use of both ONTAP commands and Cisco Nexus 3000 Series Switches commands; ONTAP commands are used unless otherwise indicated.

.Steps

. If AutoSupport is enabled on this cluster, suppress automatic case creation by invoking an AutoSupport message:
+
`system node autosupport invoke -node * -type all -message MAINT=xh`
+
where _x_ is the duration of the maintenance window in hours.
+
NOTE: The AutoSupport message notifies technical support of this maintenance task so that automatic case creation is suppressed during the maintenance window.

. Change the privilege level to advanced, entering *y* when prompted to continue:
+
`set -privilege advanced`
+
The advanced prompt (`*>`) appears.

. Display how many cluster interconnect interfaces are configured in each node for each cluster interconnect switch:
+
`network device-discovery show -protocol cdp`
+
[subs=+quotes]
----
cluster1::*> *network device-discovery show -protocol cdp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------- --------
cluster1-02/cdp
            e0a    cs1                       Eth1/2            N3K-C3132Q-V
            e0b    cs2                       Eth1/2            N3K-C3132Q-V
cluster1-01/cdp
            e0a    cs1                       Eth1/1            N3K-C3132Q-V
            e0b    cs2                       Eth1/1            N3K-C3132Q-V
----

. Check the administrative or operational status of each cluster interface.
 .. Display the network port attributes:
+
`network port show –ipspace Cluster`
+
[subs=+quotes]
----
cluster1::*> *network port show -ipspace Cluster*

Node: cluster1-02
                                                  Speed(Mbps) Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status
--------- ------------ ---------------- ---- ---- ----------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy
e0b       Cluster      Cluster          up   9000  auto/10000 healthy

Node: cluster1-01
                                                  Speed(Mbps) Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper  Status
--------- ------------ ---------------- ---- ---- ----------- ------
e0a       Cluster      Cluster          up   9000  auto/10000 healthy
e0b       Cluster      Cluster          up   9000  auto/10000 healthy
----

 .. Display information about the LIFs:
+
`network interface show -vserver Cluster`
+
[subs=+quotes]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical            Status     Network            Current       Current Is
Vserver     Interface          Admin/Oper Address/Mask       Node          Port    Home
----------- ------------------ ---------- ------------------ ------------- ------- ----
Cluster
            cluster1-01_clus1  up/up      169.254.209.69/16  cluster1-01   e0a     true
            cluster1-01_clus2  up/up      169.254.49.125/16  cluster1-01   e0b     true
            cluster1-02_clus1  up/up      169.254.47.194/16  cluster1-02   e0a     true
            cluster1-02_clus2  up/up      169.254.19.183/16  cluster1-02   e0b     true
----
. Ping the remote cluster LIFs:
+
`cluster ping-cluster -node local`
+
[subs=+quotes]
----
cluster1::*> *cluster ping-cluster -node local*
Host is cluster1-02
Getting addresses from network interface table...
Cluster cluster1-01_clus1 169.254.209.69 cluster1-01     e0a
Cluster cluster1-01_clus2 169.254.49.125 cluster1-01     e0b
Cluster cluster1-02_clus1 169.254.47.194 cluster1-02     e0a
Cluster cluster1-02_clus2 169.254.19.183 cluster1-02     e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
    Local 169.254.19.183 to Remote 169.254.209.69
    Local 169.254.19.183 to Remote 169.254.49.125
    Local 169.254.47.194 to Remote 169.254.209.69
    Local 169.254.47.194 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----

. Verify that the `auto-revert` command is enabled on all cluster LIFs:
+
`network interface show -vserver Cluster -fields auto-revert`
+
[subs=+quotes]
----
cluster1::*> *network interface show -vserver Cluster -fields auto-revert*

          Logical
Vserver   Interface           Auto-revert
--------- ––––––-------------- ------------
Cluster
          cluster1-01_clus1   true
          cluster1-01_clus2   true
          cluster1-02_clus1   true
          cluster1-02_clus2   true
----

// QA clean-up, 2022-03-03
